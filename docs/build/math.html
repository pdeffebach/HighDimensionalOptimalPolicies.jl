<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Mathematical Appendix · High Dimensional Optimal Policies</title><meta name="title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta property="og:title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta property="twitter:title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta name="description" content="Documentation for High Dimensional Optimal Policies."/><meta property="og:description" content="Documentation for High Dimensional Optimal Policies."/><meta property="twitter:description" content="Documentation for High Dimensional Optimal Policies."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">High Dimensional Optimal Policies</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li class="is-active"><a class="tocitem" href="math.html">Mathematical Appendix</a><ul class="internal"><li><a class="tocitem" href="#The-Standard-Optimal-Policy-Problem"><span>The Standard Optimal Policy Problem</span></a></li><li><a class="tocitem" href="#The-Relaxed-Optimal-Policy-Problem"><span>The Relaxed Optimal Policy Problem</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="math.html">Mathematical Appendix</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="math.html">Mathematical Appendix</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/pdeffebach/HighDimensionalOptimalPolicies.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/pdeffebach/HighDimensionalOptimalPolicies.jl/blob/master/docs/src/math.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Mathematical-Appendix"><a class="docs-heading-anchor" href="#Mathematical-Appendix">Mathematical Appendix</a><a id="Mathematical-Appendix-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Appendix" title="Permalink"></a></h1><h2 id="The-Standard-Optimal-Policy-Problem"><a class="docs-heading-anchor" href="#The-Standard-Optimal-Policy-Problem">The Standard Optimal Policy Problem</a><a id="The-Standard-Optimal-Policy-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Standard-Optimal-Policy-Problem" title="Permalink"></a></h2><p>The researcher starts with model economy which is parametrized according to estimated parameters <span>$\hat{\theta}$</span>. Denote <span>$N \in \mathcal{N}$</span> to be a &quot;policy&quot; within the the model. For any given pair of parameter estimates <span>$(\hat{\theta}, N)$</span> we can generate a welfare level <span>$W(N; \hat{\theta}) \in \mathbb{R}$</span>. In this way, we can compare policies <span>$N, N&#39; \in \mathcal{N}$</span>. </p><p>For example, the consider a model of the transportation throughout the city, where <span>$\hat{\theta}$</span> represents, among other things, the preferences of households for taking the car vs. the bus, or the speed of various transportation modes. In this example, <span>$\mathbb{N}$</span> represents the set of public transportation routes throughout the city. </p><p>The researcher wishes to advise the policy-maker on the optimal policy. That is, they want to find</p><p class="math-container">\[N^* \in \arg \max_{N} W(N; \hat{\theta})\]</p><p>Consider the case where <span>$N$</span> is high-dimensional or otherwise difficult to characterize and where <span>$\mathcal{N}$</span> either a very large discrete set or an otherwise large continuous space. In this scenario, we face two main constraints. </p><ol><li>he high dimensionality of <span>$N$</span> can make conventional descent-based optimization methods prohibitively computationally expensive. </li><li>The large state space of <span>$\mathcal{N}$</span> makes it difficult to ensure the we have correctly identified the global best policy <span>$N^*$</span> as opposed to one of many local optima. </li></ol><h2 id="The-Relaxed-Optimal-Policy-Problem"><a class="docs-heading-anchor" href="#The-Relaxed-Optimal-Policy-Problem">The Relaxed Optimal Policy Problem</a><a id="The-Relaxed-Optimal-Policy-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Relaxed-Optimal-Policy-Problem" title="Permalink"></a></h2><p>To solve these issues, we re-characterize the optimal policy problem such that our optimal policy <span>$N^*$</span> is now defined as</p><p class="math-container">\[N^* \in \arg \max W(N; \hat{\theta}) + \epsilon_N\]</p><p>where <span>$\epsilon_N$</span> is an i.i.d extreme value type-I distribution with dispersion parameter <span>$\beta$</span>. That is, a <span>$\text{Gumble}(\beta^{-1})$</span>.</p><p>In this relaxed problem, <span>$\epsilon_N$</span> is unobserved by the researcher. This might represent, for example, social welfare factors that are not in the model, or idiosyncratic policy effects that are not observed by the researcher. In the relaxed problem, <span>$\beta$</span>, the dispersion of errors <span>$\epsilon_N$</span> is also unobserved by the researcher and the researcher must make assumptions about its value. </p><p>This re-characterization of the optimal problem now implies that, from the researcher&#39;s perspective, <em>any</em> policy <span>$N \in \mathcal{N}$</span> could be the optimal policy <span>$N^*$</span>, given a high enough unobserved value of the idiosyncratic shock <span>$\epsilon_N$</span>. As a consequence, the researcher is no longer in searching for the <em>single</em> optimal policy, now seeks to characterize policies by the <em>probability</em> that a given policy is optimal. </p><p>Given standard results about multinomial logit probabilities, we define the probability that a given policy <span>$N$</span> is optimal as</p><p class="math-container">\[\mathbb{P}(N \text{optimal}) = \pi_\beta(N) = \frac{\exp{\beta W(N; \hat{\theta})}}{\sum_{N&#39; \in \mathcal{N}} \exp{\beta W(N&#39;; \hat\theta)}}\]</p><p>Given our constraints, listed above, that <span>$N$</span> is both high dimensional and <span>$\mathcal{N}$</span> is a large set, it is intractable to compute or estimate these probabilities explicitly. </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="index.html">« Introduction</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 9 January 2025 11:59">Thursday 9 January 2025</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
