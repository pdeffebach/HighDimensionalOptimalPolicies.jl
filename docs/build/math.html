<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Mathematical Appendix · High Dimensional Optimal Policies</title><meta name="title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta property="og:title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta property="twitter:title" content="Mathematical Appendix · High Dimensional Optimal Policies"/><meta name="description" content="Documentation for High Dimensional Optimal Policies."/><meta property="og:description" content="Documentation for High Dimensional Optimal Policies."/><meta property="twitter:description" content="Documentation for High Dimensional Optimal Policies."/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">High Dimensional Optimal Policies</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li class="is-active"><a class="tocitem" href="math.html">Mathematical Appendix</a><ul class="internal"><li><a class="tocitem" href="#The-Standard-Optimal-Policy-Problem"><span>The Standard Optimal Policy Problem</span></a></li><li><a class="tocitem" href="#The-Relaxed-Optimal-Policy-Problem"><span>The Relaxed Optimal Policy Problem</span></a></li><li><a class="tocitem" href="#The-Metropolis-Hastings-Algorithm-for-Calculating-Optimal-Policies"><span>The Metropolis-Hastings Algorithm for Calculating Optimal Policies</span></a></li></ul></li><li><a class="tocitem" href="optimal_transport.html">Optimal Transport Example</a></li><li><a class="tocitem" href="other_mh.html">Exploration of other MH Algorithms</a></li><li><a class="tocitem" href="references.html">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="math.html">Mathematical Appendix</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="math.html">Mathematical Appendix</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/pdeffebach/HighDimensionalOptimalPolicies.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/pdeffebach/HighDimensionalOptimalPolicies.jl/blob/main/docs/src/math.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Mathematical-Appendix"><a class="docs-heading-anchor" href="#Mathematical-Appendix">Mathematical Appendix</a><a id="Mathematical-Appendix-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-Appendix" title="Permalink"></a></h1><h2 id="The-Standard-Optimal-Policy-Problem"><a class="docs-heading-anchor" href="#The-Standard-Optimal-Policy-Problem">The Standard Optimal Policy Problem</a><a id="The-Standard-Optimal-Policy-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Standard-Optimal-Policy-Problem" title="Permalink"></a></h2><p>The researcher starts with model economy which is parametrized according to estimated parameters <span>$\hat{\theta}$</span>. Denote <span>$N \in \mathcal{N}$</span> to be a &quot;policy&quot; within the the model. For any given pair of parameter estimates <span>$(\hat{\theta}, N)$</span> we can generate a welfare level <span>$W(N; \hat{\theta}) \in \mathbb{R}$</span>. In this way, we can compare policies <span>$N, N&#39; \in \mathcal{N}$</span>. </p><p>For example, the consider a model of the transportation throughout the city, where <span>$\hat{\theta}$</span> represents, among other things, the preferences of households for taking the car vs. the bus, or the speed of various transportation modes. In this example, <span>$\mathbb{N}$</span> represents the set of public transportation routes throughout the city. </p><p>The researcher wishes to advise the policy-maker on the optimal policy. That is, they want to find</p><p class="math-container">\[N^* \in \arg \max_{N} W(N; \hat{\theta})\]</p><p>Consider the case where <span>$N$</span> is high-dimensional or otherwise difficult to characterize and where <span>$\mathcal{N}$</span> either a very large discrete set or an otherwise large continuous space. In this scenario, we face two main constraints. </p><ol><li>he high dimensionality of <span>$N$</span> can make conventional descent-based optimization methods prohibitively computationally expensive. </li><li>The large state space of <span>$\mathcal{N}$</span> makes it difficult to ensure the we have correctly identified the global best policy <span>$N^*$</span> as opposed to one of many local optima. </li></ol><h2 id="The-Relaxed-Optimal-Policy-Problem"><a class="docs-heading-anchor" href="#The-Relaxed-Optimal-Policy-Problem">The Relaxed Optimal Policy Problem</a><a id="The-Relaxed-Optimal-Policy-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#The-Relaxed-Optimal-Policy-Problem" title="Permalink"></a></h2><p>To solve these issues, we re-characterize the optimal policy problem such that our optimal policy <span>$N^*$</span> is now defined as</p><p class="math-container">\[N^* \in \arg \max W(N; \hat{\theta}) + \epsilon_N\]</p><p>where <span>$\epsilon_N$</span> is an i.i.d extreme value type-I distribution with dispersion parameter <span>$\beta$</span>. That is, a <span>$\text{Gumble}(\beta^{-1})$</span>.</p><p>In this relaxed problem, <span>$\epsilon_N$</span> is unobserved by the researcher. This might represent, for example, social welfare factors that are not in the model, or idiosyncratic policy effects that are not observed by the researcher. In the relaxed problem, <span>$\beta$</span>, the dispersion of errors <span>$\epsilon_N$</span> is also unobserved by the researcher and the researcher must make assumptions about its value. </p><p>This re-characterization of the optimal problem now implies that, from the researcher&#39;s perspective, <em>any</em> policy <span>$N \in \mathcal{N}$</span> could be the optimal policy <span>$N^*$</span>, given a high enough unobserved value of the idiosyncratic shock <span>$\epsilon_N$</span>. As a consequence, the researcher is no longer in searching for the <em>single</em> optimal policy, now seeks to characterize policies by the <em>probability</em> that a given policy is optimal. </p><p>Given standard results about multinomial logit probabilities, we define the probability that a given policy <span>$N$</span> is optimal as</p><p class="math-container">\[\mathbb{P}(N \text{optimal}) = \pi_\beta(N) = \frac{\exp{\beta W(N; \hat{\theta})}}{\sum_{N&#39; \in \mathcal{N}} \exp{\beta W(N&#39;; \hat\theta)}}\]</p><p>Our goal, then, is to estimate <span>$\pi_\beta(N)$</span>. </p><h2 id="The-Metropolis-Hastings-Algorithm-for-Calculating-Optimal-Policies"><a class="docs-heading-anchor" href="#The-Metropolis-Hastings-Algorithm-for-Calculating-Optimal-Policies">The Metropolis-Hastings Algorithm for Calculating Optimal Policies</a><a id="The-Metropolis-Hastings-Algorithm-for-Calculating-Optimal-Policies-1"></a><a class="docs-heading-anchor-permalink" href="#The-Metropolis-Hastings-Algorithm-for-Calculating-Optimal-Policies" title="Permalink"></a></h2><p>Given our constraints, listed above, that <span>$N$</span> is both high dimensional and <span>$\mathcal{N}$</span> is a large set, it is intractable to compute or estimate the probabilities <span>$\pi_\beta(N)$</span> explicitly. To compensate for this, instead of analyzing features of <span>$\pi_\beta(N)$</span>, we generate a set of &quot;likely optimal policies&quot;</p><p>Instead, our goal is to sample optimal policies from the distribution <span>$\pi_\beta(N)$</span> without fully characterizing <span>$\pi_\beta(N)$</span>. We accomplish this through the Metropolitan-Hastings algorithm. </p><p>At a high level, the Metropolitan-Hastings algorithm is a Markov Chain Monte-Carlo algorithm for sampling from a probability distribution which is difficult to characterize. It is an iterative procedure which takes as an input an initial &quot;guess&quot; of an initial Markov Chain and over time will characterize a Markov Chain whose stationary distribution corresponds to the distribution of interest. The exposition of this section borrows from Levin and Peres (2017).</p><p>Fixing ideas, consider an initial Markov chain <span>$\Psi$</span> which is both aperiodic and irreducible, and satisfies <span>$\Psi(N, N&#39;) &gt; 0 \iff \Psi(N&#39;, N) &gt; 0$</span>. Begin with network <span>$N_1$</span>. Given network <span>$N_k$</span> and step <span>$k$</span>, draw a candidate network <span>$N&#39;$</span> from the initial distribution <span>$\Psi(N&#39; \mid N_k)$</span>. This candidate network <span>$N&#39;$</span> becomes <span>$N_{k+1}$</span> with probability given</p><p class="math-container">\[\mathbb{P}(N_{k+1} = N&#39; \mid N_k) = \min \left(1, \frac{\exp(\beta W(N&#39;))\Psi(N_k \mid N&#39;)}{\exp(\beta W(N_k))\Psi(N&#39; \mid N_k)}\right)\]</p><p>To understand this expression, examine the case where <span>$\Psi(N, N&#39;) = 1 \text{ for all } N, N&#39; \in \mathcal{N}$</span>. If <span>$W(N&#39;) &gt; W(N)$</span>, then <span>$N&#39;$</span> is accepted. If <span>$W(N&#39;) &lt; W(N)$</span>, then it is accepted with a probability that is increasing in <span>$W(N&#39;)$</span>. </p><p>As <span>$k \rightarrow \infty$</span>, then <span>$\mathbb{P}(N_k = N) \rightarrow \pi_\beta(N)$</span>.  </p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="index.html">« Introduction</a><a class="docs-footer-nextpage" href="optimal_transport.html">Optimal Transport Example »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Monday 27 January 2025 12:37">Monday 27 January 2025</span>. Using Julia version 1.11.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
